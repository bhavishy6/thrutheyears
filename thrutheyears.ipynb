{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import secrets\n",
    "import contractions\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lyricsgenius\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA, DEP, LEMMA, LOWER, IS_PUNCT, IS_DIGIT, IS_SPACE, IS_STOP\n",
    "from spacy.tokens import Doc\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genius = lyricsgenius.Genius(secrets.GENIUS_ACCESS_TOKEN)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tokens(doc, index_to_del, list_attr=[LOWER, POS, ENT_TYPE, IS_ALPHA, DEP, LEMMA, LOWER, IS_PUNCT, IS_DIGIT, IS_SPACE, IS_STOP]):\n",
    "    # https://gist.github.com/Jacobe2169/5086c7c4f6c56e9d3c7cfb1eb0010fe8\n",
    "    \"\"\"\n",
    "    Remove tokens from a Spacy *Doc* object without losing \n",
    "    associated information (PartOfSpeech, Dependance, Lemma, extensions, ...)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : spacy.tokens.doc.Doc\n",
    "        spacy representation of the text\n",
    "    index_to_del : list of integer \n",
    "         positions of each token you want to delete from the document\n",
    "    list_attr : list, optional\n",
    "        Contains the Spacy attributes you want to keep (the default is \n",
    "        [LOWER, POS, ENT_TYPE, IS_ALPHA, DEP, LEMMA, LOWER, IS_PUNCT, IS_DIGIT, IS_SPACE, IS_STOP])\n",
    "    Returns\n",
    "    -------\n",
    "    spacy.tokens.doc.Doc\n",
    "        Filtered version of doc\n",
    "    \"\"\"\n",
    "    \n",
    "    np_array = doc.to_array(list_attr) # Array representation of Doc\n",
    "    \n",
    "    # Creating a mask: boolean array of the indexes to delete\n",
    "    mask_to_del = np.ones(len(np_array), np.bool)\n",
    "    mask_to_del[index_to_del] = 0\n",
    "    \n",
    "    np_array_2 = np_array[mask_to_del]\n",
    "    doc2 = Doc(doc.vocab, words=[t.text for t in doc if t.i not in index_to_del])\n",
    "    doc2.from_array(list_attr, np_array_2)\n",
    "    \n",
    "    ### Modification made by @yarongon https://gist.github.com/Jacobe2169/5086c7c4f6c56e9d3c7cfb1eb0010fe8#gistcomment-2941380\n",
    "    # Handling user extensions\n",
    "    #  The `doc.user_data` dictionary is holding the data backing user-defined attributes.\n",
    "    #  The data is based on characters offset, so a conversion is needed from the\n",
    "    #  old Doc to the new one.\n",
    "    #  More info here: https://github.com/explosion/spaCy/issues/2532\n",
    "    arr = np.arange(len(doc))\n",
    "    new_index_to_old = arr[mask_to_del]\n",
    "    doc_offset_2_token = {tok.idx : tok.i  for tok in doc}  # needed for the user data\n",
    "    doc2_token_2_offset = {tok.i : tok.idx  for tok in doc2}  # needed for the user data\n",
    "    new_user_data = {}\n",
    "    for ((prefix, ext_name, offset, x), val) in doc.user_data.items():\n",
    "        old_token_index = doc_offset_2_token[offset]\n",
    "        new_token_index = np.where(new_index_to_old == old_token_index)[0]\n",
    "        if new_token_index.size == 0:  # Case this index was deleted\n",
    "            continue\n",
    "        new_char_index = doc2_token_2_offset[new_token_index[0]]\n",
    "        new_user_data[(prefix, ext_name, new_char_index, x)] = val\n",
    "    doc2.user_data = new_user_data\n",
    "    \n",
    "    return doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=contractions.CONTRACTION_MAP):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "#     contractions_pattern = re.compile('|'.join(contraction_mapping.keys()), \n",
    "#                                       flags=re.IGNORECASE|re.DOTALL)\n",
    "#     print(contractions_pattern.pattern)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())  \n",
    "        if first_char != \"'\":\n",
    "            expanded_contraction = first_char+expanded_contraction[1:]\n",
    "#         print(match + \": \"+ expanded_contraction)\n",
    "        return expanded_contraction\n",
    "        \n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    text = expanded_text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_good_adlib(span):\n",
    "    #list of (start, end)\n",
    "    all_pos = [token.pos_ for token in span]\n",
    "    all_dep = [token.dep_ for token in span]\n",
    "    \n",
    "    #if the span contains a verb and subject, then it is a good adlib\n",
    "    if(\"VERB\" in all_pos and \"nsubj\" in all_dep):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def remove_adlibs(text):\n",
    "    lyric = nlp(text)\n",
    "    in_paranthesis = False\n",
    "    start_idx = -1\n",
    "    end_idx = -1\n",
    "    adlibs = []\n",
    "    for token in lyric:\n",
    "        if (token.text == '(' and not in_paranthesis):\n",
    "            start_idx = token.i\n",
    "            in_paranthesis = True\n",
    "        elif (token.text == ')' and in_paranthesis):\n",
    "            end_idx = token.i + 1\n",
    "            adlibs.append((start_idx, end_idx))\n",
    "            in_paranthesis = False\n",
    "    \n",
    "    bad_ranges = []\n",
    "    for (start, end) in adlibs:\n",
    "        if(not is_good_adlib(lyric[start:end])):\n",
    "            bad_ranges.append((start, end))\n",
    "            \n",
    "    #remove all words from bad ranges\n",
    "    to_remove = []\n",
    "    for (start, end) in bad_ranges:\n",
    "        for i in range(start, end):\n",
    "            to_remove.append(i)\n",
    "    \n",
    "    lyric = remove_tokens(lyric, to_remove)\n",
    "    text = str(lyric)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add spacy data\n",
    "def add_spacy_data(dataset):\n",
    "    \n",
    "    verbs = []\n",
    "    nouns = []\n",
    "    adverbs = []\n",
    "    corpus = []\n",
    "    entities = []\n",
    "    for i in range(0, len(dataset)):\n",
    "        print(\"SpaCy now processing {} by {}\".format(dataset.iloc[i]['Song Title'], dataset.iloc[i]['Artist']))\n",
    "        song = dataset.iloc[i][\"Lyrics\"]\n",
    "        doc = nlp(song)\n",
    "        spacy_df = pd.DataFrame()\n",
    "        for token in doc:\n",
    "            row = {\n",
    "                \"word\": token.text,\n",
    "                \"lemma\": token.lemma_ if token.lemma_ != \"-PRON-\" else token.text ,\n",
    "                \"pos\": token.pos_,\n",
    "                \"stop word\": token.is_stop,\n",
    "            }\n",
    "            spacy_df = spacy_df.append(row, ignore_index=True)\n",
    "        verbs.append(\" \".join(spacy_df['lemma'][spacy_df[\"pos\"] == \"VERB\"].values))\n",
    "        nouns.append(\" \".join(spacy_df['lemma'][spacy_df[\"pos\"] == \"NOUN\"].values))\n",
    "        adverbs.append(\" \".join(spacy_df['lemma'][spacy_df[\"pos\"] == \"ADV\"].values))\n",
    "        corpus1 = \" \".join(spacy_df['lemma'][spacy_df[\"stop word\"] == False].values)\n",
    "        corpus1 = re.sub(r'[^A-Za-z0-9]+', ' ', corpus1)\n",
    "        corpus.append(corpus1)\n",
    "        entities.append(\", \".join(str(ent) for ent in doc.ents))\n",
    "    dataset['Verbs'] = verbs\n",
    "    dataset['Nouns'] = nouns\n",
    "    dataset['Adverbs'] = adverbs\n",
    "    dataset['Corpus'] = corpus\n",
    "    dataset['Entities'] = entities\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_billboard_from_year(start_year, end_year):\n",
    "    years = np.arange(start_year, end_year + 1).astype(int)\n",
    "    top_songs = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, len(years)):\n",
    "        year = years[i]\n",
    "        print(\"Collecting songs from %i...\", year)\n",
    "        url = \"https://www.billboard.com/charts/year-end/\"+ str(year) +\"/hot-100-songs\"\n",
    "        \n",
    "        billboard_page = requests.get(url)\n",
    "        soup = BeautifulSoup(billboard_page.text, \"html.parser\")\n",
    "\n",
    "        titles = [div.text for div in soup.find_all(\"div\", \"ye-chart-item__title\")]\n",
    "        ranks = [div.text for div in soup.find_all(\"div\", \"ye-chart-item__rank\")]\n",
    "        artists = [div.text for div in soup.find_all(\"div\", \"ye-chart-item__artist\")]\n",
    "\n",
    "        for i in range(0, len(ranks)):\n",
    "            row = {\n",
    "                \"Rank\": ranks[i].replace(\"\\n\", \"\").strip(),\n",
    "                \"Song Title\": titles[i].replace(\"\\n\", \"\").strip(),\n",
    "                \"Artist\": artists[i].replace(\"\\n\", \"\").strip(),\n",
    "                \"Year\": int(year)\n",
    "            }\n",
    "            top_songs = top_songs.append(row, ignore_index=True)\n",
    "    return top_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_frequencies_by_year(dataset, feature_column):\n",
    "    frequencies = pd.DataFrame()\n",
    "    years = dataset[\"Year\"].unique().tolist()\n",
    "    for i in range(0, len(years)):\n",
    "        year_tokens = str(genius_spacy_data[feature_column][genius_spacy_data['Year'] == years[i]].tolist()).split(\" \")\n",
    "        word_counts = Counter(year_tokens)\n",
    "        average_tokens = \n",
    "        frequencies = frequencies.append({\n",
    "            \"Year\": years[i],\n",
    "            \"Most Common \" + feature_column: word_counts.most_common(n=100)\n",
    "        }, ignore_index=True)\n",
    "    frequencies['Year'] = frequencies['Year'].astype(int)\n",
    "    return frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_term_frequencies(dataset):\n",
    "    averages = pd.DataFrame()\n",
    "    years = dataset[\"Year\"].unique().tolist()\n",
    "    for i in range(0, len(years)):\n",
    "        row= {\n",
    "            \"Year\": years[i],\n",
    "            \"Average Words\": genius_spacy_data[\"Word Count\"][genius_spacy_data['Year'] == years[i]].mean(),\n",
    "            \"Average Unique Words\": genius_spacy_data[\"Unique Word Count\"][genius_spacy_data['Year'] ==years[i]].mean()\n",
    "        }\n",
    "        averages = averages.append(row, ignore_index = True)\n",
    "    averages['Year'] = averages['Year'].astype(int)\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting songs from %i... 2019\n"
     ]
    }
   ],
   "source": [
    "#1. get top songs from range of years\n",
    "all_songs = get_billboard_from_year(2019, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song Title</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lil Nas X Featuring Billy Ray Cyrus</td>\n",
       "      <td>1</td>\n",
       "      <td>Old Town Road</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Post Malone &amp; Swae Lee</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunflower (Spider-Man: Into The Spider-Verse)</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Halsey</td>\n",
       "      <td>3</td>\n",
       "      <td>Without Me</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>4</td>\n",
       "      <td>Bad Guy</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Post Malone</td>\n",
       "      <td>5</td>\n",
       "      <td>Wow.</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Artist Rank  \\\n",
       "0  Lil Nas X Featuring Billy Ray Cyrus    1   \n",
       "1               Post Malone & Swae Lee    2   \n",
       "2                               Halsey    3   \n",
       "3                        Billie Eilish    4   \n",
       "4                          Post Malone    5   \n",
       "\n",
       "                                      Song Title    Year  \n",
       "0                                  Old Town Road  2019.0  \n",
       "1  Sunflower (Spider-Man: Into The Spider-Verse)  2019.0  \n",
       "2                                     Without Me  2019.0  \n",
       "3                                        Bad Guy  2019.0  \n",
       "4                                           Wow.  2019.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_songs.head(5))\n",
    "display(all_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 2020-05-23 11:18:36.487095\n",
      "Searching for \"Old Town Road\" by Lil Nas X Featuring Billy Ray Cyrus...\n",
      "Done.\n",
      "Searching for \"Sunflower (Spider-Man: Into The Spider-Verse)\" by Post Malone & Swae Lee...\n",
      "Done.\n",
      "Searching for \"Without Me\" by Halsey...\n",
      "Done.\n",
      "Searching for \"Bad Guy\" by Billie Eilish...\n",
      "Done.\n",
      "Searching for \"Wow.\" by Post Malone...\n",
      "Done.\n",
      "Searching for \"Happier\" by Marshmello & Bastille...\n",
      "Done.\n",
      "Searching for \"7 Rings\" by Ariana Grande...\n",
      "Done.\n",
      "Searching for \"Talk\" by Khalid...\n",
      "Done.\n",
      "Searching for \"Sicko Mode\" by Travis Scott...\n",
      "Done.\n",
      "Searching for \"Sucker\" by Jonas Brothers...\n",
      "Done.\n",
      "Searching for \"High Hopes\" by Panic! At The Disco...\n",
      "Done.\n",
      "Searching for \"Thank U, Next\" by Ariana Grande...\n",
      "Done.\n",
      "Searching for \"Truth Hurts\" by Lizzo...\n",
      "Done.\n",
      "Searching for \"Dancing With A Stranger\" by Sam Smith & Normani...\n",
      "Done.\n",
      "Searching for \"Senorita\" by Shawn Mendes & Camila Cabello...\n",
      "Done.\n",
      "Searching for \"I Don't Care\" by Ed Sheeran & Justin Bieber...\n",
      "Done.\n",
      "Searching for \"Eastside\" by benny blanco, Halsey & Khalid...\n",
      "Done.\n",
      "Searching for \"Going Bad\" by Meek Mill Featuring Drake...\n",
      "Done.\n",
      "Searching for \"Shallow\" by Lady Gaga & Bradley Cooper...\n",
      "Done.\n",
      "Searching for \"Better\" by Khalid...\n",
      "Done.\n",
      "Searching for \"No Guidance\" by Chris Brown Featuring Drake...\n",
      "Done.\n",
      "Searching for \"Girls Like You\" by Maroon 5 Featuring Cardi B...\n",
      "Done.\n",
      "Searching for \"Sweet But Psycho\" by Ava Max...\n",
      "Done.\n",
      "Searching for \"Suge\" by DaBaby...\n",
      "Done.\n",
      "Searching for \"Middle Child\" by J. Cole...\n",
      "Done.\n",
      "Searching for \"Drip Too Hard\" by Lil Baby & Gunna...\n",
      "Done.\n",
      "Searching for \"Someone You Loved\" by Lewis Capaldi...\n",
      "Done.\n",
      "Searching for \"Ran$om\" by Lil Tecca...\n",
      "Done.\n",
      "Searching for \"If I Can't Have You\" by Shawn Mendes...\n",
      "Done.\n",
      "Searching for \"Goodbyes\" by Post Malone Featuring Young Thug...\n",
      "Done.\n",
      "Searching for \"ZEZE\" by Kodak Black Featuring Travis Scott & Offset...\n",
      "Done.\n",
      "Searching for \"Better Now\" by Post Malone...\n",
      "Done.\n",
      "Searching for \"Youngblood\" by 5 Seconds Of Summer...\n",
      "Done.\n",
      "Searching for \"Money In The Grave\" by Drake Featuring Rick Ross...\n",
      "Done.\n",
      "Searching for \"Speechless\" by Dan + Shay...\n",
      "Done.\n",
      "Searching for \"Break Up With Your Girlfriend, I'm Bored\" by Ariana Grande...\n",
      "Done.\n",
      "Searching for \"Please Me\" by Cardi B & Bruno Mars...\n",
      "Done.\n",
      "Searching for \"Money\" by Cardi B...\n",
      "Done.\n",
      "Searching for \"You Need To Calm Down\" by Taylor Swift...\n",
      "Done.\n",
      "Searching for \"Panini\" by Lil Nas X...\n",
      "Done.\n",
      "Searching for \"Look Back At It\" by A Boogie Wit da Hoodie...\n",
      "Done.\n",
      "Searching for \"A Lot\" by 21 Savage...\n",
      "Done.\n",
      "Searching for \"ME!\" by Taylor Swift Featuring Brendon Urie...\n",
      "Done.\n",
      "Searching for \"MIA\" by Bad Bunny Featuring Drake...\n",
      "Done.\n",
      "Searching for \"Pop Out\" by Polo G Featuring Lil Tjay...\n",
      "Done.\n",
      "Searching for \"Beautiful Crazy\" by Luke Combs...\n",
      "Done.\n",
      "Searching for \"Thotiana\" by Blueface...\n",
      "Done.\n",
      "Searching for \"Lucid Dreams\" by Juice WRLD...\n",
      "Done.\n",
      "Searching for \"Mo Bamba\" by Sheck Wes...\n",
      "Done.\n",
      "Searching for \"Beautiful People\" by Ed Sheeran Featuring Khalid...\n",
      "Done.\n",
      "Searching for \"Wake Up In The Sky\" by Gucci Mane X Bruno Mars X Kodak Black...\n",
      "Done.\n",
      "Searching for \"Whiskey Glasses\" by Morgan Wallen...\n",
      "Done.\n",
      "Searching for \"God's Country\" by Blake Shelton...\n",
      "Done.\n",
      "Searching for \"Be Alright\" by Dean Lewis...\n",
      "Done.\n",
      "Searching for \"Pure Water\" by Mustard & Migos...\n",
      "Done.\n",
      "Searching for \"The Git Up\" by Blanco Brown...\n",
      "Done.\n",
      "Searching for \"Taki Taki\" by DJ Snake Featuring Selena Gomez, Ozuna & Cardi B...\n",
      "Done.\n",
      "Searching for \"Close To Me\" by Ellie Goulding X Diplo Featuring Swae Lee...\n",
      "No results found for: 'Close To Me Ellie Goulding X Diplo Featuring Swae Lee'\n",
      "Searching for \"Envy Me\" by Calboy...\n",
      "Done.\n",
      "Searching for \"You Say\" by Lauren Daigle...\n",
      "Done.\n",
      "Searching for \"Hey Look Ma, I Made It\" by Panic! At The Disco...\n",
      "Done.\n",
      "Searching for \"Circles\" by Post Malone...\n",
      "Done.\n",
      "Searching for \"Beer Never Broke My Heart\" by Luke Combs...\n",
      "Done.\n",
      "Searching for \"The London\" by Young Thug, J. Cole & Travis Scott...\n",
      "Done.\n",
      "Searching for \"Con Calma\" by Daddy Yankee & Katy Perry Featuring Snow...\n",
      "Done.\n",
      "Searching for \"Murder On My Mind\" by YNW Melly...\n",
      "Done.\n",
      "Searching for \"When The Party's Over\" by Billie Eilish...\n",
      "Done.\n",
      "Searching for \"Act Up\" by City Girls...\n",
      "Done.\n",
      "Searching for \"I Like It\" by Cardi B, Bad Bunny & J Balvin...\n",
      "Done.\n",
      "Searching for \"Trampoline\" by SHAED...\n",
      "Done.\n",
      "Searching for \"Leave Me Alone\" by Flipp Dinero...\n",
      "Done.\n",
      "Searching for \"Breathin\" by Ariana Grande...\n",
      "Done.\n",
      "Searching for \"Bury A Friend\" by Billie Eilish...\n",
      "Done.\n",
      "Searching for \"Close Friends\" by Lil Baby...\n",
      "Done.\n",
      "Searching for \"Baby Shark\" by Pinkfong...\n",
      "Done.\n",
      "Searching for \"My Type\" by Saweetie...\n",
      "Done.\n",
      "Searching for \"Worth It\" by YK Osiris...\n",
      "Done.\n",
      "Searching for \"Only Human\" by Jonas Brothers...\n",
      "Done.\n",
      "Searching for \"Knockin' Boots\" by Luke Bryan...\n",
      "Done.\n",
      "Searching for \"Trip\" by Ella Mai...\n",
      "Done.\n",
      "Searching for \"Rumor\" by Lee Brice...\n",
      "Done.\n",
      "Searching for \"Swervin\" by A Boogie Wit da Hoodie Featuring 6ix9ine...\n",
      "Done.\n",
      "Searching for \"How Do You Sleep?\" by Sam Smith...\n",
      "Done.\n",
      "Searching for \"Baby\" by Lil Baby & DaBaby...\n",
      "Done.\n",
      "Searching for \"Look What God Gave Her\" by Thomas Rhett...\n",
      "Done.\n",
      "Searching for \"Good As You\" by Kane Brown...\n",
      "Done.\n",
      "Searching for \"Clout\" by Offset Featuring Cardi B...\n",
      "Done.\n",
      "Searching for \"Love Lies\" by Khalid & Normani...\n",
      "Done.\n",
      "Searching for \"One Thing Right\" by Marshmello & Kane Brown...\n",
      "Done.\n",
      "Searching for \"Cash Shit\" by Megan Thee Stallion Featuring DaBaby...\n",
      "Done.\n",
      "Searching for \"Tequila\" by Dan + Shay...\n",
      "Done.\n",
      "Searching for \"Shotta Flow\" by NLE Choppa...\n",
      "Done.\n",
      "Searching for \"Hot Girl Summer\" by Megan Thee Stallion, Nicki Minaj & Ty Dolla $ign...\n",
      "Done.\n",
      "Searching for \"Talk You Out Of It\" by Florida Georgia Line...\n",
      "Done.\n",
      "Searching for \"Beautiful\" by Bazzi Featuring Camila Cabello...\n",
      "Done.\n",
      "Searching for \"Eyes On You\" by Chase Rice...\n",
      "Done.\n",
      "Searching for \"All To Myself\" by Dan + Shay...\n",
      "Done.\n",
      "Searching for \"Boyfriend\" by Ariana Grande & Social House...\n",
      "Done.\n",
      "Searching for \"Walk Me Home\" by P!nk...\n",
      "Done.\n",
      "Searching for \"Robbery\" by Juice WRLD...\n",
      "Done.\n",
      "Finished Job: 2020-05-23 11:24:13.245890\n",
      "Elapsed Time: 0:05:36.758795\n"
     ]
    }
   ],
   "source": [
    "#2. search & copy data from genius for each song\n",
    "\n",
    "starttime = datetime.now()\n",
    "print(\"Starting: \" + str(starttime))\n",
    "all_song_data = pd.DataFrame()\n",
    "for i in range(0, len(all_songs)):\n",
    "    song = all_songs.iloc[i]\n",
    "\n",
    "    try:\n",
    "        song_data = genius.search_song(song['Song Title'], song[\"Artist\"])\n",
    "#         print(dir(song_data))\n",
    "        if(song_data):\n",
    "            song_album = song_data.album\n",
    "            featured_artists = song_data.featured_artists\n",
    "            song_lyrics = song_data.lyrics.replace(\"\\n\", \" \")\n",
    "            song_media = song_data.media\n",
    "            song_url = song_data.url\n",
    "            song_writer_artists = song_data.writer_artists\n",
    "            song_producer_artists = song_data.producer_artists if song_data.producer_artists else \"\"\n",
    "            song_album_url = song_data.album_url\n",
    "            song_release_year = song_data.year\n",
    "    except:\n",
    "        song_album = \"null\"\n",
    "        song_album_url = \"null\"\n",
    "        featured_artists = \"null\"\n",
    "        song_lyrics = \"null\"\n",
    "        song_media = \"null\"\n",
    "        song_url = \"null\"\n",
    "        song_writer_artists = \"null\"\n",
    "        song_release_year = \"null\"\n",
    "        song_producer_artists = song_data.producer_artists\n",
    "        song_album_url = song_data.album_url\n",
    "        song_release_year = song_data.year\n",
    "        \n",
    "    row = {\n",
    "        \"Year\": song['Year'],\n",
    "        \"Charting Rank\": song['Rank'],\n",
    "        \"Song Title\": song['Song Title'],\n",
    "        \"Artist\": song['Artist'],\n",
    "        \"Album\": song_album ,\n",
    "        \"Producers\": song_producer_artists,\n",
    "        \"Writers\": song_writer_artists,\n",
    "        \"Album URL\": song_album_url,\n",
    "        \"Featured Artists\": featured_artists,\n",
    "        \"Lyrics\":  song_lyrics,\n",
    "        \"URL\": song_url,\n",
    "        \"Media\": song_media,\n",
    "        \"Release Year\": song_release_year\n",
    "    }\n",
    "    all_song_data = all_song_data.append(row, ignore_index=True)\n",
    "\n",
    "endtime = datetime.now()\n",
    "print(\"Finished Job: \" + str(endtime))\n",
    "print(\"Elapsed Time: \" + str(endtime - starttime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to file. \n",
    "# genius_song_data = all_song_data\n",
    "# genius_song_data.to_pickle(r\"stored_song_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from file\n",
    "genius_song_data = pd.read_pickle(\"stored_song_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. clean the lyric data\n",
    "importlib.reload(contractions)\n",
    "for i in range(0, len(genius_song_data)):\n",
    "    song = genius_song_data.iloc[i]\n",
    "    expanded = expand_contractions(song['Lyrics'])\n",
    "    cleaned = remove_adlibs(expanded)\n",
    "    genius_song_data.at[i, 'Lyrics'] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy now processing Old Town Road by Lil Nas X Featuring Billy Ray Cyrus\n",
      "SpaCy now processing Sunflower (Spider-Man: Into The Spider-Verse) by Post Malone & Swae Lee\n",
      "SpaCy now processing Without Me by Halsey\n",
      "SpaCy now processing Bad Guy by Billie Eilish\n",
      "SpaCy now processing Wow. by Post Malone\n",
      "SpaCy now processing Happier by Marshmello & Bastille\n",
      "SpaCy now processing 7 Rings by Ariana Grande\n",
      "SpaCy now processing Talk by Khalid\n",
      "SpaCy now processing Sicko Mode by Travis Scott\n",
      "SpaCy now processing Sucker by Jonas Brothers\n",
      "SpaCy now processing High Hopes by Panic! At The Disco\n",
      "SpaCy now processing Thank U, Next by Ariana Grande\n",
      "SpaCy now processing Truth Hurts by Lizzo\n",
      "SpaCy now processing Dancing With A Stranger by Sam Smith & Normani\n",
      "SpaCy now processing Senorita by Shawn Mendes & Camila Cabello\n",
      "SpaCy now processing I Don't Care by Ed Sheeran & Justin Bieber\n",
      "SpaCy now processing Eastside by benny blanco, Halsey & Khalid\n",
      "SpaCy now processing Going Bad by Meek Mill Featuring Drake\n",
      "SpaCy now processing Shallow by Lady Gaga & Bradley Cooper\n",
      "SpaCy now processing Better by Khalid\n",
      "SpaCy now processing No Guidance by Chris Brown Featuring Drake\n",
      "SpaCy now processing Girls Like You by Maroon 5 Featuring Cardi B\n",
      "SpaCy now processing Sweet But Psycho by Ava Max\n",
      "SpaCy now processing Suge by DaBaby\n",
      "SpaCy now processing Middle Child by J. Cole\n",
      "SpaCy now processing Drip Too Hard by Lil Baby & Gunna\n",
      "SpaCy now processing Someone You Loved by Lewis Capaldi\n",
      "SpaCy now processing Ran$om by Lil Tecca\n",
      "SpaCy now processing If I Can't Have You by Shawn Mendes\n",
      "SpaCy now processing Goodbyes by Post Malone Featuring Young Thug\n",
      "SpaCy now processing ZEZE by Kodak Black Featuring Travis Scott & Offset\n",
      "SpaCy now processing Better Now by Post Malone\n",
      "SpaCy now processing Youngblood by 5 Seconds Of Summer\n",
      "SpaCy now processing Money In The Grave by Drake Featuring Rick Ross\n",
      "SpaCy now processing Speechless by Dan + Shay\n",
      "SpaCy now processing Break Up With Your Girlfriend, I'm Bored by Ariana Grande\n",
      "SpaCy now processing Please Me by Cardi B & Bruno Mars\n",
      "SpaCy now processing Money by Cardi B\n",
      "SpaCy now processing You Need To Calm Down by Taylor Swift\n",
      "SpaCy now processing Panini by Lil Nas X\n",
      "SpaCy now processing Look Back At It by A Boogie Wit da Hoodie\n",
      "SpaCy now processing A Lot by 21 Savage\n",
      "SpaCy now processing ME! by Taylor Swift Featuring Brendon Urie\n",
      "SpaCy now processing MIA by Bad Bunny Featuring Drake\n",
      "SpaCy now processing Pop Out by Polo G Featuring Lil Tjay\n",
      "SpaCy now processing Beautiful Crazy by Luke Combs\n",
      "SpaCy now processing Thotiana by Blueface\n",
      "SpaCy now processing Lucid Dreams by Juice WRLD\n",
      "SpaCy now processing Mo Bamba by Sheck Wes\n",
      "SpaCy now processing Beautiful People by Ed Sheeran Featuring Khalid\n",
      "SpaCy now processing Wake Up In The Sky by Gucci Mane X Bruno Mars X Kodak Black\n",
      "SpaCy now processing Whiskey Glasses by Morgan Wallen\n",
      "SpaCy now processing God's Country by Blake Shelton\n",
      "SpaCy now processing Be Alright by Dean Lewis\n",
      "SpaCy now processing Pure Water by Mustard & Migos\n",
      "SpaCy now processing The Git Up by Blanco Brown\n",
      "SpaCy now processing Taki Taki by DJ Snake Featuring Selena Gomez, Ozuna & Cardi B\n",
      "SpaCy now processing Close To Me by Ellie Goulding X Diplo Featuring Swae Lee\n",
      "SpaCy now processing Envy Me by Calboy\n",
      "SpaCy now processing You Say by Lauren Daigle\n",
      "SpaCy now processing Hey Look Ma, I Made It by Panic! At The Disco\n",
      "SpaCy now processing Circles by Post Malone\n",
      "SpaCy now processing Beer Never Broke My Heart by Luke Combs\n",
      "SpaCy now processing The London by Young Thug, J. Cole & Travis Scott\n",
      "SpaCy now processing Con Calma by Daddy Yankee & Katy Perry Featuring Snow\n",
      "SpaCy now processing Murder On My Mind by YNW Melly\n",
      "SpaCy now processing When The Party's Over by Billie Eilish\n",
      "SpaCy now processing Act Up by City Girls\n",
      "SpaCy now processing I Like It by Cardi B, Bad Bunny & J Balvin\n",
      "SpaCy now processing Trampoline by SHAED\n",
      "SpaCy now processing Leave Me Alone by Flipp Dinero\n",
      "SpaCy now processing Breathin by Ariana Grande\n",
      "SpaCy now processing Bury A Friend by Billie Eilish\n",
      "SpaCy now processing Close Friends by Lil Baby\n",
      "SpaCy now processing Baby Shark by Pinkfong\n",
      "SpaCy now processing My Type by Saweetie\n",
      "SpaCy now processing Worth It by YK Osiris\n",
      "SpaCy now processing Only Human by Jonas Brothers\n",
      "SpaCy now processing Knockin' Boots by Luke Bryan\n",
      "SpaCy now processing Trip by Ella Mai\n",
      "SpaCy now processing Rumor by Lee Brice\n",
      "SpaCy now processing Swervin by A Boogie Wit da Hoodie Featuring 6ix9ine\n",
      "SpaCy now processing How Do You Sleep? by Sam Smith\n",
      "SpaCy now processing Baby by Lil Baby & DaBaby\n",
      "SpaCy now processing Look What God Gave Her by Thomas Rhett\n",
      "SpaCy now processing Good As You by Kane Brown\n",
      "SpaCy now processing Clout by Offset Featuring Cardi B\n",
      "SpaCy now processing Love Lies by Khalid & Normani\n",
      "SpaCy now processing One Thing Right by Marshmello & Kane Brown\n",
      "SpaCy now processing Cash Shit by Megan Thee Stallion Featuring DaBaby\n",
      "SpaCy now processing Tequila by Dan + Shay\n",
      "SpaCy now processing Shotta Flow by NLE Choppa\n",
      "SpaCy now processing Hot Girl Summer by Megan Thee Stallion, Nicki Minaj & Ty Dolla $ign\n",
      "SpaCy now processing Talk You Out Of It by Florida Georgia Line\n",
      "SpaCy now processing Beautiful by Bazzi Featuring Camila Cabello\n",
      "SpaCy now processing Eyes On You by Chase Rice\n",
      "SpaCy now processing All To Myself by Dan + Shay\n",
      "SpaCy now processing Boyfriend by Ariana Grande & Social House\n",
      "SpaCy now processing Walk Me Home by P!nk\n",
      "SpaCy now processing Robbery by Juice WRLD\n"
     ]
    }
   ],
   "source": [
    "#4. add spacy data\n",
    "genius_spacy_data = add_spacy_data(genius_song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save data to file\n",
    "# genius_spacy_data.to_pickle(r\"stored_song_data_with_spacy.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from file\n",
    "genius_spacy_data =  pd.read_pickle(\"stored_song_data_with_spacy.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4a. calculate count of unique words in year, average words per songs\n",
    "word_counts = []\n",
    "unique_counts = []\n",
    "for i in range(0, len(genius_spacy_data)):\n",
    "    word_counts.append(len(genius_spacy_data.iloc[i]['Lyrics'].split()))\n",
    "    unique_counts.append(len(set(genius_spacy_data.iloc[i]['Lyrics'].split())))\n",
    "genius_spacy_data['Word Count'] = word_counts\n",
    "genius_spacy_data['Unique Word Count'] = unique_counts\n",
    "\n",
    "year_summary = get_average_term_frequencies(genius_spacy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to file\n",
    "genius_spacy_data.to_pickle(r\"stored_song_data_with_spacy_word_counts.pickle\")\n",
    "year_summary.to_pickle(r\"yearly_averages.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from file\n",
    "# genius_spacy_data =  pd.read_pickle(\"stored_song_data_with_spacy_word_counts.pickle\")\n",
    "# year_summary = pd.read_pickle(\"yearly_averages.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album</th>\n",
       "      <th>Album URL</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Charting Rank</th>\n",
       "      <th>Featured Artists</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Media</th>\n",
       "      <th>Producers</th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Song Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Writers</th>\n",
       "      <th>Year</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Unique Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diplo Presents Thomas Wesley, Chapter 1: Snake...</td>\n",
       "      <td>https://genius.com/albums/Diplo/Diplo-presents...</td>\n",
       "      <td>Lil Nas X Featuring Billy Ray Cyrus</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Intro: Billy Ray Cyrus] Oh, oh-oh Oh  [Refrai...</td>\n",
       "      <td>[{'attribution': 'diplo', 'provider': 'soundcl...</td>\n",
       "      <td>[{'api_path': '/artists/1756072', 'header_imag...</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>Old Town Road</td>\n",
       "      <td>https://genius.com/Lil-nas-x-billy-ray-cyrus-a...</td>\n",
       "      <td>[{'api_path': '/artists/60166', 'header_image_...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>go take go ride can go take go ride can get at...</td>\n",
       "      <td>refrain horse town road horse town road horse ...</td>\n",
       "      <td>til more til more up now down so back til more...</td>\n",
       "      <td>Intro Billy Ray Cyrus oh oh oh oh refrain Bil...</td>\n",
       "      <td>Intro, Billy Ray Cyrus, Billy Ray Cyrus, Verse...</td>\n",
       "      <td>388</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Post Malone &amp; Swae Lee</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>Author: Jorge Ramos You did read it, and it wi...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>Sunflower (Spider-Man: Into The Spider-Verse)</td>\n",
       "      <td>https://genius.com/Jorja-smith-virtual-reality...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>read will happen join perform schedule will ta...</td>\n",
       "      <td>author list artist reality concert place app h...</td>\n",
       "      <td>recently so most back also when together later...</td>\n",
       "      <td>author Jorge Ramos read happen Post Malone rec...</td>\n",
       "      <td>Jorge Ramos, 17, October, Raleigh, PNC Arena, ...</td>\n",
       "      <td>672</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manic (Target Exclusive)</td>\n",
       "      <td>https://genius.com/albums/Halsey/Manic-target-...</td>\n",
       "      <td>Halsey</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Verse 1] Found you when your heart was broke ...</td>\n",
       "      <td>[{'provider': 'youtube', 'start': 0, 'type': '...</td>\n",
       "      <td>[{'api_path': '/artists/143754', 'header_image...</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>Without Me</td>\n",
       "      <td>https://genius.com/Halsey-without-me-lyrics</td>\n",
       "      <td>[{'api_path': '/artists/2080714', 'header_imag...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>find break fill overflow take keep keep leave ...</td>\n",
       "      <td>heart cup knee foot advantage one name sky one...</td>\n",
       "      <td>when so far then then right back just how up t...</td>\n",
       "      <td>Verse 1 find heart break fill cup overflow ta...</td>\n",
       "      <td>[Pre-Chorus, sittin, Feelin, Thinkin, Hundred,...</td>\n",
       "      <td>445</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WHEN WE ALL FALL ASLEEP, WHERE DO WE GO? (Japa...</td>\n",
       "      <td>https://genius.com/albums/Billie-eilish/When-w...</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Verse 1] White shirt now red, my bloody nose ...</td>\n",
       "      <td>[{'native_uri': 'spotify:track:2Fxmhks0bxGSBdJ...</td>\n",
       "      <td>[{'api_path': '/artists/615565', 'header_image...</td>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>Bad Guy</td>\n",
       "      <td>https://genius.com/Billie-eilish-bad-guy-lyrics</td>\n",
       "      <td>[{'api_path': '/artists/615550', 'header_image...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>know think say thank want want can make make m...</td>\n",
       "      <td>shirt nose toe creepin one bruise knee soul gu...</td>\n",
       "      <td>now around so when so so really just always so...</td>\n",
       "      <td>Verse 1 white shirt red bloody nose Sleepin t...</td>\n",
       "      <td>Verse 1] White, Sleepin, Creepin, Bruises, Pos...</td>\n",
       "      <td>267</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hollywood’s Bleeding</td>\n",
       "      <td>https://genius.com/albums/Post-malone/Hollywoo...</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Verse 1] Said she tired of little money, need...</td>\n",
       "      <td>[{'provider': 'youtube', 'start': 6, 'type': '...</td>\n",
       "      <td>[{'api_path': '/artists/143754', 'header_image...</td>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>Wow.</td>\n",
       "      <td>https://genius.com/Post-malone-wow-lyrics</td>\n",
       "      <td>[{'api_path': '/artists/28169', 'header_image_...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>say tire need pull need mix get fall know piss...</td>\n",
       "      <td>money boy inch blade flockin shawty vodka hous...</td>\n",
       "      <td>now up up back when when deep when when probab...</td>\n",
       "      <td>Verse 1 say tire little money need big boy pu...</td>\n",
       "      <td>20 inch, Shawty, LaCroix, G-Wagen, G-Wagen, G-...</td>\n",
       "      <td>405</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Album  \\\n",
       "0  Diplo Presents Thomas Wesley, Chapter 1: Snake...   \n",
       "1                                               None   \n",
       "2                           Manic (Target Exclusive)   \n",
       "3  WHEN WE ALL FALL ASLEEP, WHERE DO WE GO? (Japa...   \n",
       "4                               Hollywood’s Bleeding   \n",
       "\n",
       "                                           Album URL  \\\n",
       "0  https://genius.com/albums/Diplo/Diplo-presents...   \n",
       "1                                               None   \n",
       "2  https://genius.com/albums/Halsey/Manic-target-...   \n",
       "3  https://genius.com/albums/Billie-eilish/When-w...   \n",
       "4  https://genius.com/albums/Post-malone/Hollywoo...   \n",
       "\n",
       "                                Artist Charting Rank Featured Artists  \\\n",
       "0  Lil Nas X Featuring Billy Ray Cyrus             1               []   \n",
       "1               Post Malone & Swae Lee             2               []   \n",
       "2                               Halsey             3               []   \n",
       "3                        Billie Eilish             4               []   \n",
       "4                          Post Malone             5               []   \n",
       "\n",
       "                                              Lyrics  \\\n",
       "0  [Intro: Billy Ray Cyrus] Oh, oh-oh Oh  [Refrai...   \n",
       "1  Author: Jorge Ramos You did read it, and it wi...   \n",
       "2  [Verse 1] Found you when your heart was broke ...   \n",
       "3  [Verse 1] White shirt now red, my bloody nose ...   \n",
       "4  [Verse 1] Said she tired of little money, need...   \n",
       "\n",
       "                                               Media  \\\n",
       "0  [{'attribution': 'diplo', 'provider': 'soundcl...   \n",
       "1                                                 []   \n",
       "2  [{'provider': 'youtube', 'start': 0, 'type': '...   \n",
       "3  [{'native_uri': 'spotify:track:2Fxmhks0bxGSBdJ...   \n",
       "4  [{'provider': 'youtube', 'start': 6, 'type': '...   \n",
       "\n",
       "                                           Producers Release Year  \\\n",
       "0  [{'api_path': '/artists/1756072', 'header_imag...   2019-05-02   \n",
       "1                                                      2019-10-07   \n",
       "2  [{'api_path': '/artists/143754', 'header_image...   2018-10-04   \n",
       "3  [{'api_path': '/artists/615565', 'header_image...   2019-03-29   \n",
       "4  [{'api_path': '/artists/143754', 'header_image...   2018-12-24   \n",
       "\n",
       "                                      Song Title  \\\n",
       "0                                  Old Town Road   \n",
       "1  Sunflower (Spider-Man: Into The Spider-Verse)   \n",
       "2                                     Without Me   \n",
       "3                                        Bad Guy   \n",
       "4                                           Wow.   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://genius.com/Lil-nas-x-billy-ray-cyrus-a...   \n",
       "1  https://genius.com/Jorja-smith-virtual-reality...   \n",
       "2        https://genius.com/Halsey-without-me-lyrics   \n",
       "3    https://genius.com/Billie-eilish-bad-guy-lyrics   \n",
       "4          https://genius.com/Post-malone-wow-lyrics   \n",
       "\n",
       "                                             Writers    Year  \\\n",
       "0  [{'api_path': '/artists/60166', 'header_image_...  2019.0   \n",
       "1                                                 []  2019.0   \n",
       "2  [{'api_path': '/artists/2080714', 'header_imag...  2019.0   \n",
       "3  [{'api_path': '/artists/615550', 'header_image...  2019.0   \n",
       "4  [{'api_path': '/artists/28169', 'header_image_...  2019.0   \n",
       "\n",
       "                                               Verbs  \\\n",
       "0  go take go ride can go take go ride can get at...   \n",
       "1  read will happen join perform schedule will ta...   \n",
       "2  find break fill overflow take keep keep leave ...   \n",
       "3  know think say thank want want can make make m...   \n",
       "4  say tire need pull need mix get fall know piss...   \n",
       "\n",
       "                                               Nouns  \\\n",
       "0  refrain horse town road horse town road horse ...   \n",
       "1  author list artist reality concert place app h...   \n",
       "2  heart cup knee foot advantage one name sky one...   \n",
       "3  shirt nose toe creepin one bruise knee soul gu...   \n",
       "4  money boy inch blade flockin shawty vodka hous...   \n",
       "\n",
       "                                             Adverbs  \\\n",
       "0  til more til more up now down so back til more...   \n",
       "1  recently so most back also when together later...   \n",
       "2  when so far then then right back just how up t...   \n",
       "3  now around so when so so really just always so...   \n",
       "4  now up up back when when deep when when probab...   \n",
       "\n",
       "                                              Corpus  \\\n",
       "0   Intro Billy Ray Cyrus oh oh oh oh refrain Bil...   \n",
       "1  author Jorge Ramos read happen Post Malone rec...   \n",
       "2   Verse 1 find heart break fill cup overflow ta...   \n",
       "3   Verse 1 white shirt red bloody nose Sleepin t...   \n",
       "4   Verse 1 say tire little money need big boy pu...   \n",
       "\n",
       "                                            Entities  Word Count  \\\n",
       "0  Intro, Billy Ray Cyrus, Billy Ray Cyrus, Verse...         388   \n",
       "1  Jorge Ramos, 17, October, Raleigh, PNC Arena, ...         672   \n",
       "2  [Pre-Chorus, sittin, Feelin, Thinkin, Hundred,...         445   \n",
       "3  Verse 1] White, Sleepin, Creepin, Bruises, Pos...         267   \n",
       "4  20 inch, Shawty, LaCroix, G-Wagen, G-Wagen, G-...         405   \n",
       "\n",
       "   Unique Word Count  \n",
       "0                110  \n",
       "1                376  \n",
       "2                144  \n",
       "3                138  \n",
       "4                207  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(genius_spacy_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4b. calculate common terms and counts of each\n",
    "adverbs_frequencies = get_feature_frequencies_by_year(genius_spacy_data, \"Adverbs\")\n",
    "nouns_frequencies = get_feature_frequencies_by_year(genius_spacy_data, \"Nouns\")\n",
    "verbs_frequencies = get_feature_frequencies_by_year(genius_spacy_data, \"Verbs\")\n",
    "word_frequencies = get_feature_frequencies_by_year(genius_spacy_data, \"Corpus\")\n",
    "entity_frequencies = get_feature_frequencies_by_year(genius_spacy_data, \"Entities\")\n",
    "\n",
    "adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Most Common Nouns    [(feat, 279), (bitch, 155), (shit, 140), (baby...\n",
       "Year                                                              2019\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Most Common Verbs    [(get, 463), (know, 319), (be, 285), (say, 270...\n",
       "Year                                                              2019\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Most Common Adverbs    [(just, 238), (when, 237), (so, 211), (now, 16...\n",
       "Year                                                                2019\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Most Common Corpus    [(2018, 1639), (yeah, 653), (like, 459), (get,...\n",
       "Year                                                               2019\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Most Common Entities    [(2018,, 1423), (&, 235), (2017,, 157), (the, ...\n",
       "Year                                                                 2019\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Unique Words</th>\n",
       "      <th>Average Words</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228.87</td>\n",
       "      <td>592.53</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Unique Words  Average Words  Year\n",
       "0                228.87         592.53  2019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(nouns_frequencies.iloc[0])\n",
    "display(verbs_frequencies.iloc[0])\n",
    "display(adverbs_frequencies.iloc[0])\n",
    "display(word_frequencies.iloc[0])\n",
    "display(entity_frequencies.iloc[0])\n",
    "\n",
    "display(year_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "ti =5 #3 = humble 5 = bad and boujee\n",
    "song = genius_spacy_data.iloc[ti]\n",
    "lyrics = song['Lyrics']\n",
    "lyrics_contr = expand_contractions(lyrics)\n",
    "doc = nlp(lyrics_contr)\n",
    "cleaned = remove_adlibs(lyrics_contr)\n",
    "print (cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to get this back as a string\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "doc = nlp(\"i want to get this back as a string\")\n",
    "print(str(doc))\n",
    "assert str(doc) == \"i want to get this back as a string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.rand(10, 5), columns=['A', 'B', 'C', 'D', 'E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.146719</td>\n",
       "      <td>0.069909</td>\n",
       "      <td>0.388172</td>\n",
       "      <td>0.213258</td>\n",
       "      <td>0.777216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.430206</td>\n",
       "      <td>0.588375</td>\n",
       "      <td>0.097673</td>\n",
       "      <td>0.706828</td>\n",
       "      <td>0.455461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.898796</td>\n",
       "      <td>0.637269</td>\n",
       "      <td>0.612052</td>\n",
       "      <td>0.085287</td>\n",
       "      <td>0.505442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396513</td>\n",
       "      <td>0.625571</td>\n",
       "      <td>0.441940</td>\n",
       "      <td>0.531714</td>\n",
       "      <td>0.304634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113844</td>\n",
       "      <td>0.415921</td>\n",
       "      <td>0.271192</td>\n",
       "      <td>0.197504</td>\n",
       "      <td>0.927510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E\n",
       "0  0.146719  0.069909  0.388172  0.213258  0.777216\n",
       "1  0.430206  0.588375  0.097673  0.706828  0.455461\n",
       "2  0.898796  0.637269  0.612052  0.085287  0.505442\n",
       "3  0.396513  0.625571  0.441940  0.531714  0.304634\n",
       "4  0.113844  0.415921  0.271192  0.197504  0.927510"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fa36847e20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())\n",
    "df.plot.box()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
